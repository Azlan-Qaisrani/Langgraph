{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zrQF3mX37yNh0ETtF7I53ZjxMI7esZnL",
      "authorship_tag": "ABX9TyPeM0KFOYWRJY/9XJzCnJiv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azlan-Qaisrani/Langgraph/blob/main/AGENTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain-core langgraph-prebuilt sentence-transformers faiss-cpu python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIZO7AIdCTNG",
        "outputId": "7d2aab68-d836-42ef-d95c-0242ef2b5ba9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: langgraph-prebuilt in /usr/local/lib/python3.12/dist-packages (1.0.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOmi9VrJCoP0",
        "outputId": "fe1953ce-5783-4306-81ed-af0f4a310804"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (3.0.3)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.9.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing import List,TypedDict\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "Q4k56LO5BGak"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XiJbj7lzApIy"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"GRPC_VERBOSITY\"] = \"NONE\"\n",
        "os.environ[\"GRPC_TRACE\"] = \"\"\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"\"          # â† This kills the 404 error\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"\"  # extra safety\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    google_api_key=userdata.get(\"google_api_key\"),\n",
        "    temperature=0.7\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List[HumanMessage]"
      ],
      "metadata": {
        "id": "Lx8hjYfsA_vV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(state: AgentState) -> AgentState:\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    print(f\"\\nAI: {response.content}\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "lsEboNi_DATA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"process\", process)\n",
        "graph.add_edge(START, \"process\")\n",
        "graph.add_edge(\"process\", END)\n",
        "agent = graph.compile()"
      ],
      "metadata": {
        "id": "d7QdThZeDYD7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Enter: \")\n",
        "while user_input != \"exit\":\n",
        "    agent.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
        "    user_input = input(\"Enter: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhCo6tcxDzQ8",
        "outputId": "8e545850-516a-4088-c4af-b09b986422db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter: hi\n",
            "\n",
            "AI: Hi there! How can I help you today?\n",
            "Enter: my name is  Azlan tell me a joke\n",
            "\n",
            "AI: Okay, Azlan, here's a joke for you:\n",
            "\n",
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n",
            "Enter: now can you explain langgraph\n",
            "\n",
            "AI: Okay, let's break down LangGraph. In essence, LangGraph is a framework designed to make it easier to build and manage complex, multi-agent conversations and workflows using Large Language Models (LLMs). It's like a graph-based orchestrator for LLM-powered applications.\n",
            "\n",
            "Here's a more detailed explanation, covering the key concepts:\n",
            "\n",
            "**1. The Problem LangGraph Solves:**\n",
            "\n",
            "*   **Complex Conversations:** Many LLM applications go beyond simple question-and-answer interactions. They involve multi-step processes, loops, decision-making based on previous outputs, and potentially multiple agents interacting with each other.\n",
            "*   **Orchestration Challenges:**  Managing this complexity with traditional programming approaches can be cumbersome and difficult to maintain.  You need to keep track of state, handle branching logic, and ensure smooth transitions between different stages of the conversation.\n",
            "*   **Agent Collaboration:**  In some scenarios, you might want multiple LLM-powered agents to work together on a task, each with their own specialized knowledge or tools.  This requires a way to route information between agents and coordinate their actions.\n",
            "*   **Observability:**  Understanding what's happening in a complex conversation flow is crucial for debugging, monitoring, and improving the application.\n",
            "\n",
            "**2. Core Concepts of LangGraph:**\n",
            "\n",
            "*   **Graph Representation:** The fundamental idea is to represent the conversation flow as a directed graph.\n",
            "    *   **Nodes:**  Nodes in the graph represent *states* or *actions* in the conversation.  They can be things like:\n",
            "        *   **LLM Calls:**  A node that uses an LLM to generate text, answer a question, or perform a task.\n",
            "        *   **Tool Calls:** A node that executes a tool (e.g., a search engine, a database query, a calculator).\n",
            "        *   **State Updates:**  A node that updates the state of the conversation (e.g., storing information, setting flags).\n",
            "        *   **Conditional Logic:** A node that makes a decision based on the current state and directs the flow to different branches.\n",
            "    *   **Edges:** Edges define the transitions between nodes.  They specify how the conversation moves from one state/action to the next.  Edges can be:\n",
            "        *   **Unconditional:** The flow always moves to the next node.\n",
            "        *   **Conditional:** The flow moves to a specific node based on a condition (e.g., the output of an LLM call, the value of a variable).\n",
            "\n",
            "*   **State:** LangGraph maintains a state object that represents the current state of the conversation. This state is passed between nodes and can be updated by nodes.  The state typically includes:\n",
            "    *   **Conversation History:** A record of the messages exchanged so far.\n",
            "    *   **Variables:** Data that is relevant to the conversation, such as user preferences, search results, or intermediate calculations.\n",
            "    *   **Flags:** Boolean values that indicate certain conditions are met.\n",
            "\n",
            "*   **Agents:** LangGraph enables the creation of multi-agent systems where each agent is essentially a node or a subgraph within the main graph.  You can define the roles, responsibilities, and communication protocols for each agent.\n",
            "\n",
            "**3. How LangGraph Works (Simplified):**\n",
            "\n",
            "1.  **Define the Graph:** You define the nodes (states/actions) and edges (transitions) that make up your conversation flow. This is done programmatically using LangGraph's API.\n",
            "2.  **Initialize the State:** You create an initial state object that contains the starting information for the conversation.\n",
            "3.  **Run the Graph:** You start the execution of the graph. LangGraph manages the traversal of the graph, executing the nodes in the correct order based on the edges and conditions.\n",
            "4.  **Update the State:** As each node is executed, it can update the state object. The updated state is then passed to the next node.\n",
            "5.  **Repeat:** Steps 3 and 4 are repeated until the graph reaches a terminal node (a node that indicates the end of the conversation).\n",
            "\n",
            "**4. Benefits of Using LangGraph:**\n",
            "\n",
            "*   **Modularity:**  Break down complex conversations into smaller, more manageable components (nodes).\n",
            "*   **Flexibility:**  Easily define branching logic, loops, and conditional flows.\n",
            "*   **Reusability:**  Nodes can be reused in different parts of the graph or in different applications.\n",
            "*   **Scalability:**  Handle complex, multi-agent conversations.\n",
            "*   **Observability:**  Track the execution of the graph and monitor the state of the conversation for debugging and analysis.  LangGraph integrates with tracing tools.\n",
            "*   **Agent Collaboration:** Facilitate communication and coordination between multiple LLM-powered agents.\n",
            "*   **Improved Maintainability:**  The graph-based representation makes it easier to understand and modify the conversation flow.\n",
            "\n",
            "**5. Key LangGraph Components (in Python):**\n",
            "\n",
            "*   **`StateGraph`:** The main class for defining the graph.\n",
            "*   **`State`:** A class to define the state object.\n",
            "*   **`Node`:** Represents a state or action in the graph.  Nodes can be functions, chains, or other LangChain components.\n",
            "*   **`Edge`:** Defines the transitions between nodes.\n",
            "*   **`ConditionalEdge`:**  An edge that moves to a different node based on a condition.\n",
            "*   **`checkpoint`:** LangGraph supports checkpointing to save and restore the state of a graph execution.\n",
            "\n",
            "**6.  Example Scenario (Simplified):**\n",
            "\n",
            "Imagine a customer service chatbot that helps users troubleshoot a technical issue.\n",
            "\n",
            "*   **Nodes:**\n",
            "    *   `GreetUser`: Greets the user and asks about the issue.\n",
            "    *   `GetProblemDescription`:  Asks the user to describe the problem in detail.\n",
            "    *   `SearchKnowledgeBase`: Searches a knowledge base for solutions based on the problem description.\n",
            "    *   `PresentSolutions`: Presents the solutions to the user.\n",
            "    *   `AskIfHelpful`: Asks the user if the solutions were helpful.\n",
            "    *   `EscalateToHuman`: If the solutions were not helpful, escalate the issue to a human agent.\n",
            "    *   `EndConversation`: Ends the conversation.\n",
            "\n",
            "*   **Edges:**\n",
            "    *   `GreetUser` -> `GetProblemDescription` (unconditional)\n",
            "    *   `GetProblemDescription` -> `SearchKnowledgeBase` (unconditional)\n",
            "    *   `SearchKnowledgeBase` -> `PresentSolutions` (unconditional)\n",
            "    *   `PresentSolutions` -> `AskIfHelpful` (unconditional)\n",
            "    *   `AskIfHelpful` -> `EndConversation` (if user says \"yes\")\n",
            "    *   `AskIfHelpful` -> `EscalateToHuman` (if user says \"no\")\n",
            "\n",
            "**7.  Relationship to LangChain:**\n",
            "\n",
            "LangGraph is built on top of LangChain.  It leverages LangChain's components (chains, models, tools, etc.) to define the nodes in the graph.  LangGraph provides the orchestration and management layer for complex workflows built with LangChain.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "LangGraph is a powerful framework for building complex, multi-agent LLM applications by representing the conversation flow as a graph. It simplifies the orchestration of LLM calls, tool usage, and state management, leading to more maintainable, scalable, and observable applications. It's especially useful when dealing with scenarios that require more than just a simple question-and-answer interaction.\n",
            "Enter: what is my name\n",
            "\n",
            "AI: As a large language model, I have no memory of past conversations and therefore do not know your name. You have not told me your name.\n",
            "Enter: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "from typing import Union\n",
        "class AgentState(TypedDict):\n",
        "  message:List[Union[HumanMessage,AIMessage]]\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "OW6jK7DWEUZs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(state: AgentState) -> AgentState:\n",
        "    response = llm.invoke(state[\"message\"])\n",
        "    state['message'].append(AIMessage(content=response.content))\n",
        "\n",
        "    print(f\"\\nAI: {response.content}\")\n",
        "    print(\"CURRENTSTATE: \" ,state['message'])\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "5jnDQt-UOOMd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"process\", process)\n",
        "graph.add_edge(START, \"process\")\n",
        "graph.add_edge(\"process\", END)\n",
        "agent = graph.compile()"
      ],
      "metadata": {
        "id": "VS65guFLOs5k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_history=[]\n",
        "user_input=input(\"Enter: \")\n",
        "while user_input != \"exit\":\n",
        "    conversation_history.append(HumanMessage(content=user_input))\n",
        "    results=agent.invoke({\"message\": conversation_history})\n",
        "    conversation_history=results['message']\n",
        "    user_input = input(\"Enter: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJW2cDymO0m4",
        "outputId": "93ce7767-e3cc-47b3-e15a-da1ea10c8c87"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter: hi\n",
            "\n",
            "AI: Hi there! How can I help you today?\n",
            "CURRENTSTATE:  [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={})]\n",
            "Enter: myself AZLAN QAISRANI\n",
            "\n",
            "AI: It's nice to meet you, Azlan Qaisrani! How can I help you today? Is there anything you'd like to know, or anything I can do for you?\n",
            "CURRENTSTATE:  [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='myself AZLAN QAISRANI', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's nice to meet you, Azlan Qaisrani! How can I help you today? Is there anything you'd like to know, or anything I can do for you?\", additional_kwargs={}, response_metadata={})]\n",
            "Enter: define MACHine learning\n",
            "\n",
            "AI: Machine learning (ML) is a subfield of artificial intelligence (AI) that focuses on the development of computer systems that can learn from and make predictions or decisions based on data, without being explicitly programmed.\n",
            "\n",
            "Here's a breakdown of the key aspects:\n",
            "\n",
            "*   **Learning from Data:** Instead of being given specific instructions for every possible scenario, machine learning algorithms are trained on large datasets. These datasets contain examples of the relationships and patterns that the algorithm needs to learn.\n",
            "\n",
            "*   **Algorithms:**  ML uses various algorithms to analyze data, identify patterns, and build models. Common types of algorithms include:\n",
            "\n",
            "    *   **Supervised Learning:** The algorithm is trained on labeled data (input data paired with the correct output). It learns to map inputs to outputs. Examples: Regression (predicting continuous values) and Classification (predicting categories).\n",
            "    *   **Unsupervised Learning:** The algorithm is trained on unlabeled data. It tries to find hidden structures, patterns, or relationships in the data. Examples: Clustering (grouping similar data points) and Dimensionality Reduction (reducing the number of variables while preserving important information).\n",
            "    *   **Reinforcement Learning:** The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions. It aims to learn a policy that maximizes the cumulative reward.\n",
            "\n",
            "*   **Making Predictions or Decisions:** Once trained, the model can be used to make predictions on new, unseen data. This could involve predicting a customer's likelihood of buying a product, identifying spam emails, or diagnosing diseases.\n",
            "\n",
            "*   **Improving Performance:**  Machine learning algorithms are designed to improve their performance over time as they are exposed to more data. They continuously refine their models based on new information, leading to more accurate predictions and better decision-making.\n",
            "\n",
            "**In simpler terms:**\n",
            "\n",
            "Imagine you want to teach a computer to recognize cats in pictures. Instead of writing a program that explicitly defines what a cat looks like (e.g., pointy ears, whiskers, etc.), you show the computer thousands of pictures of cats and tell it, \"These are cats.\"  The machine learning algorithm analyzes these pictures and learns the patterns and features that are common to cats. Then, when you show it a new picture, it can (hopefully) correctly identify whether it's a cat or not.\n",
            "\n",
            "**Key Benefits of Machine Learning:**\n",
            "\n",
            "*   **Automation:** Automates tasks that would be difficult or impossible for humans to do.\n",
            "*   **Improved Accuracy:** Can often achieve higher accuracy than traditional programming methods.\n",
            "*   **Scalability:** Can handle large amounts of data.\n",
            "*   **Adaptability:** Can adapt to changing data and environments.\n",
            "*   **Data-Driven Insights:** Can uncover hidden patterns and insights in data.\n",
            "\n",
            "**Examples of Machine Learning in Action:**\n",
            "\n",
            "*   **Spam filters**\n",
            "*   **Recommendation systems (Netflix, Amazon)**\n",
            "*   **Fraud detection**\n",
            "*   **Self-driving cars**\n",
            "*   **Medical diagnosis**\n",
            "*   **Image recognition**\n",
            "*   **Natural Language Processing (NLP) - like chatbots and translation tools**\n",
            "\n",
            "In essence, machine learning is about enabling computers to learn from data and make intelligent decisions without explicit programming. It's a powerful tool with a wide range of applications that are transforming various industries.\n",
            "CURRENTSTATE:  [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='myself AZLAN QAISRANI', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's nice to meet you, Azlan Qaisrani! How can I help you today? Is there anything you'd like to know, or anything I can do for you?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='define MACHine learning', additional_kwargs={}, response_metadata={}), AIMessage(content='Machine learning (ML) is a subfield of artificial intelligence (AI) that focuses on the development of computer systems that can learn from and make predictions or decisions based on data, without being explicitly programmed.\\n\\nHere\\'s a breakdown of the key aspects:\\n\\n*   **Learning from Data:** Instead of being given specific instructions for every possible scenario, machine learning algorithms are trained on large datasets. These datasets contain examples of the relationships and patterns that the algorithm needs to learn.\\n\\n*   **Algorithms:**  ML uses various algorithms to analyze data, identify patterns, and build models. Common types of algorithms include:\\n\\n    *   **Supervised Learning:** The algorithm is trained on labeled data (input data paired with the correct output). It learns to map inputs to outputs. Examples: Regression (predicting continuous values) and Classification (predicting categories).\\n    *   **Unsupervised Learning:** The algorithm is trained on unlabeled data. It tries to find hidden structures, patterns, or relationships in the data. Examples: Clustering (grouping similar data points) and Dimensionality Reduction (reducing the number of variables while preserving important information).\\n    *   **Reinforcement Learning:** The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions. It aims to learn a policy that maximizes the cumulative reward.\\n\\n*   **Making Predictions or Decisions:** Once trained, the model can be used to make predictions on new, unseen data. This could involve predicting a customer\\'s likelihood of buying a product, identifying spam emails, or diagnosing diseases.\\n\\n*   **Improving Performance:**  Machine learning algorithms are designed to improve their performance over time as they are exposed to more data. They continuously refine their models based on new information, leading to more accurate predictions and better decision-making.\\n\\n**In simpler terms:**\\n\\nImagine you want to teach a computer to recognize cats in pictures. Instead of writing a program that explicitly defines what a cat looks like (e.g., pointy ears, whiskers, etc.), you show the computer thousands of pictures of cats and tell it, \"These are cats.\"  The machine learning algorithm analyzes these pictures and learns the patterns and features that are common to cats. Then, when you show it a new picture, it can (hopefully) correctly identify whether it\\'s a cat or not.\\n\\n**Key Benefits of Machine Learning:**\\n\\n*   **Automation:** Automates tasks that would be difficult or impossible for humans to do.\\n*   **Improved Accuracy:** Can often achieve higher accuracy than traditional programming methods.\\n*   **Scalability:** Can handle large amounts of data.\\n*   **Adaptability:** Can adapt to changing data and environments.\\n*   **Data-Driven Insights:** Can uncover hidden patterns and insights in data.\\n\\n**Examples of Machine Learning in Action:**\\n\\n*   **Spam filters**\\n*   **Recommendation systems (Netflix, Amazon)**\\n*   **Fraud detection**\\n*   **Self-driving cars**\\n*   **Medical diagnosis**\\n*   **Image recognition**\\n*   **Natural Language Processing (NLP) - like chatbots and translation tools**\\n\\nIn essence, machine learning is about enabling computers to learn from data and make intelligent decisions without explicit programming. It\\'s a powerful tool with a wide range of applications that are transforming various industries.', additional_kwargs={}, response_metadata={})]\n",
            "Enter: who am i\n",
            "\n",
            "AI: You are Azlan Qaisrani, as you mentioned earlier. Since I am an AI, I don't know anything about you beyond that name. To know more about who you are, I would need you to tell me more!\n",
            "CURRENTSTATE:  [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='myself AZLAN QAISRANI', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's nice to meet you, Azlan Qaisrani! How can I help you today? Is there anything you'd like to know, or anything I can do for you?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='define MACHine learning', additional_kwargs={}, response_metadata={}), AIMessage(content='Machine learning (ML) is a subfield of artificial intelligence (AI) that focuses on the development of computer systems that can learn from and make predictions or decisions based on data, without being explicitly programmed.\\n\\nHere\\'s a breakdown of the key aspects:\\n\\n*   **Learning from Data:** Instead of being given specific instructions for every possible scenario, machine learning algorithms are trained on large datasets. These datasets contain examples of the relationships and patterns that the algorithm needs to learn.\\n\\n*   **Algorithms:**  ML uses various algorithms to analyze data, identify patterns, and build models. Common types of algorithms include:\\n\\n    *   **Supervised Learning:** The algorithm is trained on labeled data (input data paired with the correct output). It learns to map inputs to outputs. Examples: Regression (predicting continuous values) and Classification (predicting categories).\\n    *   **Unsupervised Learning:** The algorithm is trained on unlabeled data. It tries to find hidden structures, patterns, or relationships in the data. Examples: Clustering (grouping similar data points) and Dimensionality Reduction (reducing the number of variables while preserving important information).\\n    *   **Reinforcement Learning:** The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions. It aims to learn a policy that maximizes the cumulative reward.\\n\\n*   **Making Predictions or Decisions:** Once trained, the model can be used to make predictions on new, unseen data. This could involve predicting a customer\\'s likelihood of buying a product, identifying spam emails, or diagnosing diseases.\\n\\n*   **Improving Performance:**  Machine learning algorithms are designed to improve their performance over time as they are exposed to more data. They continuously refine their models based on new information, leading to more accurate predictions and better decision-making.\\n\\n**In simpler terms:**\\n\\nImagine you want to teach a computer to recognize cats in pictures. Instead of writing a program that explicitly defines what a cat looks like (e.g., pointy ears, whiskers, etc.), you show the computer thousands of pictures of cats and tell it, \"These are cats.\"  The machine learning algorithm analyzes these pictures and learns the patterns and features that are common to cats. Then, when you show it a new picture, it can (hopefully) correctly identify whether it\\'s a cat or not.\\n\\n**Key Benefits of Machine Learning:**\\n\\n*   **Automation:** Automates tasks that would be difficult or impossible for humans to do.\\n*   **Improved Accuracy:** Can often achieve higher accuracy than traditional programming methods.\\n*   **Scalability:** Can handle large amounts of data.\\n*   **Adaptability:** Can adapt to changing data and environments.\\n*   **Data-Driven Insights:** Can uncover hidden patterns and insights in data.\\n\\n**Examples of Machine Learning in Action:**\\n\\n*   **Spam filters**\\n*   **Recommendation systems (Netflix, Amazon)**\\n*   **Fraud detection**\\n*   **Self-driving cars**\\n*   **Medical diagnosis**\\n*   **Image recognition**\\n*   **Natural Language Processing (NLP) - like chatbots and translation tools**\\n\\nIn essence, machine learning is about enabling computers to learn from data and make intelligent decisions without explicit programming. It\\'s a powerful tool with a wide range of applications that are transforming various industries.', additional_kwargs={}, response_metadata={}), HumanMessage(content='who am i', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You are Azlan Qaisrani, as you mentioned earlier. Since I am an AI, I don't know anything about you beyond that name. To know more about who you are, I would need you to tell me more!\", additional_kwargs={}, response_metadata={})]\n",
            "Enter: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"logging.txt\", \"w\") as file:\n",
        "    file.write(\"Your Conversation Log:\\n\")\n",
        "\n",
        "    for message in conversation_history:\n",
        "        if isinstance(message, HumanMessage):\n",
        "            file.write(f\"You: {message.content}\\n\")\n",
        "        elif isinstance(message, AIMessage):\n",
        "            file.write(f\"AI: {message.content}\\n\\n\")\n",
        "    file.write(\"End of Conversation\")\n",
        "\n",
        "print(\"Conversation saved to logging.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnMuN4-aPHzb",
        "outputId": "17323914-cfa1-443e-f600-999ee4b1358b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation saved to logging.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ALL_JlCjPt6G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6uUly1cPzaM"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}